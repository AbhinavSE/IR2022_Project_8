{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X0SvBgI8-_ub","executionInfo":{"status":"ok","timestamp":1650452628555,"user_tz":-330,"elapsed":14046,"user":{"displayName":"Abhinav Suresh Ennazhiyil","userId":"02866869318925835569"}},"outputId":"74d991e3-59d0-413d-d812-4752446e0e01"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n","Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n","Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.6)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n","Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n","Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.8)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n","Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2021.10.8)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n","Collecting mir_eval\n","  Downloading mir_eval-0.7.tar.gz (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 4.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.21.6)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.4.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from mir_eval) (0.16.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.15.0)\n","Building wheels for collected packages: mir-eval\n","  Building wheel for mir-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mir-eval: filename=mir_eval-0.7-py3-none-any.whl size=100721 sha256=54f88327b13eeecdb1f91c1353278f97734d66cf0e466ff201daf4137d85e032\n","  Stored in directory: /root/.cache/pip/wheels/18/5a/46/d2527ff1fd975e1a793375e6ed763bfe4d3ea396b7cdc470eb\n","Successfully built mir-eval\n","Installing collected packages: mir-eval\n","Successfully installed mir-eval-0.7\n"]}],"source":["!pip install librosa\n","!pip install mir_eval"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21548,"status":"ok","timestamp":1650452650096,"user":{"displayName":"Abhinav Suresh Ennazhiyil","userId":"02866869318925835569"},"user_tz":-330},"id":"PhCH-pTtHAHw","outputId":"5b3ae0ab-2d1d-42d1-a91d-1e2df404b823"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"YcgqexjdAbH7","executionInfo":{"status":"ok","timestamp":1650452656151,"user_tz":-330,"elapsed":6060,"user":{"displayName":"Abhinav Suresh Ennazhiyil","userId":"02866869318925835569"}}},"outputs":[],"source":["import librosa\n","import librosa.display as dsp\n","import mir_eval\n","from IPython.display import Audio\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pandas as pd\n","import re\n","import math\n","import numpy as np\n","from PIL import Image\n","import joblib\n","import cv2\n","from keras.utils import np_utils\n","from sklearn.model_selection import train_test_split\n","from tensorflow import keras\n","import tensorflow as tf \n","import random\n","from keras.models import Sequential\n","from keras.models import Model\n","from keras import initializers\n","from keras import optimizers\n","# from keras.utils import plot_model\n","from keras.layers import *\n","import pandas as pd\n","from tqdm.notebook import tqdm\n","import pathlib\n","import io\n","from six.moves.urllib.request import urlopen\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"D2mNt_E2Adwv","executionInfo":{"status":"ok","timestamp":1650452657037,"user_tz":-330,"elapsed":889,"user":{"displayName":"Abhinav Suresh Ennazhiyil","userId":"02866869318925835569"}}},"outputs":[],"source":["def create_spectrogram_file(inp_file):\n","    y, sr = librosa.load(inp_file)\n","    melspectrogram_array = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128,fmax=8000)\n","    mel = librosa.power_to_db(melspectrogram_array)\n","    # Length and Width of Spectogram\n","    fig_size = plt.rcParams[\"figure.figsize\"]\n","    fig_size[0] = float(mel.shape[1]) // float(100)\n","    fig_size[1] = float(mel.shape[0]) // float(100)\n","    plt.rcParams[\"figure.figsize\"] = fig_size\n","    plt.axis('off')\n","    plt.axes([0., 0., 1., 1.0], frameon=False, xticks=[], yticks=[])\n","    librosa.display.specshow(mel, cmap='gray_r')\n","    op_file = \"/content/drive/MyDrive/IR Project/Test_Spectogram_Images/\"+inp_file.split(\"/\")[-1].split(\".\")[0]+\".jpg\"\n","    plt.savefig(op_file, bbox_inches=None, pad_inches=0)\n","    plt.close()\n","    return op_file\n","    \n","def create_spectrogram(verbose=0, mode=None, continue_=6647):\n","    if mode == \"Train\":\n","        if os.path.exists('/content/drive/MyDrive/IR Project/Train_Spectogram_Images'):\n","            return\n","        # Get Genres and Track IDs from the tracks.csv file\n","        filename_metadata = \"/content/drive/MyDrive/IR Project/Data/fma_metadata/tracks.csv\"\n","        tracks = pd.read_csv(filename_metadata, header=2, low_memory=False)\n","        tracks_array = tracks.values\n","        tracks_id_array = tracks_array[: , 0]\n","        tracks_genre_array = tracks_array[: , 40]\n","        tracks_id_array = tracks_id_array.reshape(tracks_id_array.shape[0], )\n","        tracks_genre_array = tracks_genre_array.reshape(tracks_genre_array.shape[0], )\n","        folder_sample = \"/content/drive/MyDrive/IR Project/Data/fma_small\"\n","        directories = [d for d in os.listdir(folder_sample)\n","                       if os.path.isdir(os.path.join(folder_sample, d))]\n","        counter = 0\n","        if(verbose > 0):\n","            print(\"Converting mp3 audio files into mel Spectograms ...\")\n","        if not os.path.exists('/content/drive/MyDrive/IR Project/Train_Spectogram_Images'):\n","            os.makedirs('/content/drive/MyDrive/IR Project/Train_Spectogram_Images')\n","        labels = [os.path.join(folder_sample, d) for d in directories]\n","        total = 0\n","        for l in labels:\n","            total += len([f for f in os.listdir(l) if f.endswith(\".mp3\")])\n","        with tqdm(total = total) as pbar:\n","            for d in directories:\n","                label_directory = os.path.join(folder_sample, d)\n","                file_names = [os.path.join(label_directory, f)\n","                            for f in os.listdir(label_directory)\n","                            if f.endswith(\".mp3\")]\n","\n","                # Convert .mp3 files into mel-Spectograms\n","                for f in file_names:\n","                    counter += 1\n","                    pbar.update(1)\n","                    if counter <= continue_:\n","                        continue\n","                    track_id = int(re.search('/content/drive/MyDrive/IR Project/Data/fma_small/.*/(.+?).mp3', f).group(1))\n","                    try:\n","                        track_index = list(tracks_id_array).index(track_id)\n","                    except ValueError:\n","                        print(f\"Error: Track ID {track_id} not found in tracks.csv file.\")\n","                        continue\n","                    if(str(tracks_genre_array[track_index]) != '0'):\n","                        try:\n","                            y, sr = librosa.load(f)\n","                        except Exception:\n","                            print(f\"Couldn't convert {track_id}\")\n","                        melspectrogram_array = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128,fmax=8000)\n","                        mel = librosa.power_to_db(melspectrogram_array)\n","                        # Length and Width of Spectogram\n","                        fig_size = plt.rcParams[\"figure.figsize\"]\n","                        fig_size[0] = float(mel.shape[1]) // float(100)\n","                        fig_size[1] = float(mel.shape[0]) // float(100)\n","                        plt.rcParams[\"figure.figsize\"] = fig_size\n","                        plt.axis('off')\n","                        plt.axes([0., 0., 1., 1.0], frameon=False, xticks=[], yticks=[])\n","                        librosa.display.specshow(mel, cmap='gray_r')\n","                        plt.savefig(\"/content/drive/MyDrive/IR Project/Train_Spectogram_Images/\"+str(counter)+\"_\"+str(tracks_genre_array[track_index])+\".jpg\", bbox_inches=None, pad_inches=0)\n","                        plt.close()\n","                    \n","        return\n","\n","    elif mode == \"Test\":\n","        if os.path.exists('/content/drive/MyDrive/IR Project/Test_Spectogram_Images'):\n","            return\n","\n","        folder_sample = \"/content/drive/MyDrive/IR Project/Data/DLMusicTest_30\"\n","        counter = 0\n","        if(verbose > 0):\n","            print(\"Converting mp3 audio files into mel Spectograms ...\")\n","        if not os.path.exists('/content/drive/MyDrive/IR Project/Test_Sepctogram_Images'):\n","            os.makedirs('/content/drive/MyDrive/IR Project/Test_Spectogram_Images')\n","        file_names = [os.path.join(folder_sample, f) for f in os.listdir(folder_sample)\n","                       if f.endswith(\".mp3\")]\n","        # Convert .mp3 files into mel-Spectograms\n","        for f in file_names:\n","            test_id = re.search('/content/drive/MyDrive/IR Project/Data/DLMusicTest_30/(.+?).mp3', f).group(1)\n","            y, sr = librosa.load(f)\n","            melspectrogram_array = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128,fmax=8000)\n","            mel = librosa.power_to_db(melspectrogram_array)\n","            # Length and Width of Spectogram\n","            fig_size = plt.rcParams[\"figure.figsize\"]\n","            fig_size[0] = float(mel.shape[1]) // float(100)\n","            fig_size[1] = float(mel.shape[0]) // float(100)\n","            plt.rcParams[\"figure.figsize\"] = fig_size\n","            plt.axis('off')\n","            plt.axes([0., 0., 1., 1.0], frameon=False, xticks=[], yticks=[])\n","            librosa.display.specshow(mel, cmap='gray_r')\n","            plt.savefig(\"/content/drive/MyDrive/IR Project/Test_Spectogram_Images/\"+test_id+\".jpg\", cmap='gray_r', bbox_inches=None, pad_inches=0)\n","            plt.close()\n","        return"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"nQZIK8fFGn4V","executionInfo":{"status":"ok","timestamp":1650452657039,"user_tz":-330,"elapsed":890,"user":{"displayName":"Abhinav Suresh Ennazhiyil","userId":"02866869318925835569"}}},"outputs":[],"source":["def slice_spect_file(inp_file):\n","    img = Image.open(inp_file)\n","    subsample_size = 128\n","    width, height = img.size\n","    number_of_samples = width // subsample_size\n","    op_files = []\n","    counter = 0\n","    for i in range(number_of_samples):\n","        start = i*subsample_size\n","        img_temporary = img.crop((start, 0., start + subsample_size, subsample_size))\n","        op_file = \"/content/drive/MyDrive/IR Project/Test_Sliced_Images/\"+str(counter)+\"_\"+inp_file.split(\"/\")[-1]\n","        img_temporary.save(op_file)\n","        op_files.append(op_file)\n","        counter = counter + 1\n","    return op_files\n","    \n","def slice_spect(verbose=0, mode=None):\n","    if mode==\"Train\":\n","        if os.path.exists('/content/drive/MyDrive/IR Project/Train_Sliced_Images'):\n","            return\n","        labels = []\n","        image_folder = \"/content/drive/MyDrive/IR Project/Train_Spectogram_Images\"\n","        filenames = [os.path.join(image_folder, f) for f in os.listdir(image_folder)\n","                       if f.endswith(\".jpg\")]\n","        counter = 0\n","        if(verbose > 0):\n","            print(\"Slicing Spectograms ...\")\n","        if not os.path.exists('/content/drive/MyDrive/IR Project/Train_Sliced_Images'):\n","            os.makedirs('/content/drive/MyDrive/IR Project/Train_Sliced_Images')\n","        for f in tqdm(filenames):\n","            genre_variable = re.search('/content/drive/MyDrive/IR Project/Train_Spectogram_Images/.*_(.+?).jpg', f).group(1)\n","            img = Image.open(f)\n","            subsample_size = 128\n","            width, height = img.size\n","            number_of_samples = width // subsample_size\n","            for i in range(number_of_samples):\n","                start = i*subsample_size\n","                img_temporary = img.crop((start, 0., start + subsample_size, subsample_size))\n","                img_temporary.save(\"/content/drive/MyDrive/IR Project/Train_Sliced_Images/\"+str(counter)+\"_\"+genre_variable+\".jpg\")\n","                counter = counter + 1\n","        return\n","\n","    elif mode==\"Test\":\n","        if os.path.exists('/content/drive/MyDrive/IR Project/Test_Sliced_Images'):\n","            return\n","        labels = []\n","        image_folder = \"/content/drive/MyDrive/IR Project/Test_Spectogram_Images\"\n","        filenames = [os.path.join(image_folder, f) for f in os.listdir(image_folder)\n","                       if f.endswith(\".jpg\")]\n","        counter = 0\n","        if(verbose > 0):\n","            print(\"Slicing Spectograms ...\")\n","        if not os.path.exists('/content/drive/MyDrive/IR Project/Test_Sliced_Images'):\n","            os.makedirs('/content/drive/MyDrive/IR Project/Test_Sliced_Images')\n","        for f in filenames:\n","            song_variable = re.search('/content/drive/MyDrive/IR Project/Test_Spectogram_Images/(.+?).jpg', f).group(1)\n","            img = Image.open(f)\n","            subsample_size = 128\n","            width, height = img.size\n","            number_of_samples = width // subsample_size\n","            for i in range(number_of_samples):\n","                start = i*subsample_size\n","                img_temporary = img.crop((start, 0., start + subsample_size, subsample_size))\n","                img_temporary.save(\"/content/drive/MyDrive/IR Project/Test_Sliced_Images/\"+str(counter)+\"_\"+song_variable+\".jpg\")\n","                counter = counter + 1\n","        return"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"rqDB2VIdHPko","executionInfo":{"status":"ok","timestamp":1650452657039,"user_tz":-330,"elapsed":8,"user":{"displayName":"Abhinav Suresh Ennazhiyil","userId":"02866869318925835569"}}},"outputs":[],"source":["def get_data(inp_file):\n","    print(\"Creating Spectogram...\")\n","    op_file = create_spectrogram_file(inp_file)\n","    print(\"Slicing Spectogram...\")\n","    filenames = slice_spect_file(op_file)\n","    print(\"Converting to numpy array\")\n","    images_all = [None]*(len(filenames))\n","    index = 0\n","    for f in filenames:\n","        temp = cv2.imread(f, cv2.IMREAD_UNCHANGED)\n","        images_all[index] = cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY)\n","        index += 1\n","    images = np.array(images_all)\n","    return images\n","\n","def get_data_online_url(url):\n","    print(\"Fetching File from URL...\")\n","    z = io.BytesIO(urlopen(url).read())\n","    file_path = '/content/drive/MyDrive/IR Project/Data/test/'+url.split(\"/\")[-1]\n","    pathlib.Path(file_path).write_bytes(z.getbuffer())\n","    return get_data(file_path)\n","\n","def load_dataset(verbose=0, mode=None, datasetSize=1.0):\n","    if os.path.exists('/content/drive/MyDrive/IR Project/Training_Data'):\n","            train_x = np.load(\"/content/drive/MyDrive/IR Project/Training_Data/train_x.npy\")\n","            train_y = np.load(\"/content/drive/MyDrive/IR Project/Training_Data/train_y.npy\")\n","            test_x = np.load(\"/content/drive/MyDrive/IR Project/Training_Data/test_x.npy\")\n","            test_y = np.load(\"/content/drive/MyDrive/IR Project/Training_Data/test_y.npy\")\n","            n_classes, genre_new = joblib.load(\"/content/drive/MyDrive/IR Project/Training_Data/meta.pkl\")\n","            return train_x, train_y, test_x, test_y, n_classes, genre_new\n","    create_spectrogram(verbose, mode)\n","    slice_spect(verbose, mode)\n","\n","    # datasetSize is a float value which returns a fraction of the dataset.\n","    # If set as 1.0 it returns the entire dataset.\n","    # If set as 0.5 it returns half the dataset.\n","\n","    if mode==\"Train\":\n","        genre = {\n","        \"Hip-Hop\": 0,\n","        \"International\": 1,\n","        \"Electronic\": 2,\n","        \"Folk\" : 3,\n","        \"Experimental\": 4,\n","        \"Rock\": 5,\n","        \"Pop\": 6,\n","        \"Instrumental\": 7\n","        }\n","        if(verbose > 0):\n","            print(\"Compiling Training and Testing Sets ...\")\n","        filenames = [os.path.join(\"/content/drive/MyDrive/IR Project/Train_Sliced_Images\", f) for f in os.listdir(\"/content/drive/MyDrive/IR Project/Train_Sliced_Images\")\n","                       if f.endswith(\".jpg\")]\n","        images_all = [None]*(len(filenames))\n","        labels_all = [None]*(len(filenames))\n","        for f in tqdm(filenames):\n","            index = int(re.search('/content/drive/MyDrive/IR Project/Train_Sliced_Images/(.+?)_.*.jpg', f).group(1))\n","            genre_variable = re.search('/content/drive/MyDrive/IR Project/Train_Sliced_Images/.*_(.+?).jpg', f).group(1)\n","            temp = cv2.imread(f, cv2.IMREAD_UNCHANGED)\n","            images_all[index] = cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY)\n","            labels_all[index] = genre[genre_variable]\n","\n","        if(datasetSize == 1.0):\n","            images = images_all\n","            labels = labels_all\n","\n","        else:\n","            count_max = int(len(images_all)*datasetSize / 8.0)\n","            count_array = [0, 0, 0, 0, 0 ,0, 0, 0]\n","            images = []\n","            labels = []\n","            for i in range(0, len(images_all)):\n","                if(count_array[labels_all[i]] < count_max):\n","                    images.append(images_all[i])\n","                    labels.append(labels_all[i])\n","                    count_array[labels_all[i]] += 1\n","            images = np.array(images)\n","            labels = np.array(labels)\n","\n","        images = np.array(images)\n","        labels = np.array(labels)\n","        labels = labels.reshape(labels.shape[0],1)\n","        train_x, test_x, train_y, test_y = train_test_split(images, labels, test_size=0.05, shuffle=True)\n","\n","        # Convert the labels into one-hot vectors.\n","        train_y = np_utils.to_categorical(train_y)\n","        test_y = np_utils.to_categorical(test_y, num_classes=8)\n","        n_classes = len(genre)\n","        genre_new = {value: key for key, value in genre.items()}\n","\n","        if not os.path.exists('/content/drive/MyDrive/IR Project/Training_Data'):\n","            os.makedirs('/content/drive/MyDrive/IR Project/Training_Data')\n","        np.save(\"/content/drive/MyDrive/IR Project/Training_Data/train_x.npy\", train_x)\n","        np.save(\"/content/drive/MyDrive/IR Project/Training_Data/train_y.npy\", train_y)\n","        np.save(\"/content/drive/MyDrive/IR Project/Training_Data/test_x.npy\", test_x)\n","        np.save(\"/content/drive/MyDrive/IR Project/Training_Data/test_y.npy\", test_y)\n","        joblib.dump((n_classes, genre_new), \"/content/drive/MyDrive/IR Project/Training_Data/meta.pkl\")\n","        return train_x, train_y, test_x, test_y, n_classes, genre_new\n","\n","    if mode==\"Test\":\n","        if(verbose > 0):\n","            print(\"Compiling Training and Testing Sets ...\")\n","        filenames = [os.path.join(\"/content/drive/MyDrive/IR Project/Test_Sliced_Images\", f) for f in os.listdir(\"/content/drive/MyDrive/IR Project/Test_Sliced_Images\")\n","                       if f.endswith(\".jpg\")]\n","        images = []\n","        labels = []\n","        for f in filenames:\n","            song_variable = re.search('/content/drive/MyDrive/IR Project/Test_Sliced_Images/.*_(.+?).jpg', f).group(1)\n","            tempImg = cv2.imread(f, cv2.IMREAD_UNCHANGED)\n","            images.append(cv2.cvtColor(tempImg, cv2.COLOR_BGR2GRAY))\n","            labels.append(song_variable)\n","\n","        images = np.array(images)\n","\n","        return images, labels"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14390,"status":"ok","timestamp":1650452671421,"user":{"displayName":"Abhinav Suresh Ennazhiyil","userId":"02866869318925835569"},"user_tz":-330},"id":"7FwcZ3WSKGUJ","outputId":"bdfae240-5f6f-4b3a-d609-8424c474d36c"},"outputs":[{"output_type":"stream","name":"stdout","text":["yes\n"]}],"source":["train_x, train_y, test_x, test_y, n_classes, genre = load_dataset(verbose=1, mode=\"Train\", datasetSize=0.75)\n","# datasetSize = 0.75, this returns 3/4th of the dataset.\n","\n","# Expand the dimensions of the image to have a channel dimension. (nx128x128) ==> (nx128x128x1)\n","train_x = train_x.reshape(train_x.shape[0], train_x.shape[1], train_x.shape[2], 1)\n","test_x = test_x.reshape(test_x.shape[0], test_x.shape[1], test_x.shape[2], 1)\n","\n","# Normalize the matrices.\n","train_x = train_x / 255.\n","test_x = test_x / 255."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1001013,"status":"ok","timestamp":1650455594474,"user":{"displayName":"Abhinav Suresh Ennazhiyil","userId":"02866869318925835569"},"user_tz":-330},"id":"wNiXSZGFHmsB","outputId":"ecd76a61-91db-478a-9847-39f1960ab03e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 122, 122, 64)      3200      \n","                                                                 \n"," batch_normalization (BatchN  (None, 122, 122, 64)     256       \n"," ormalization)                                                   \n","                                                                 \n"," average_pooling2d (AverageP  (None, 61, 61, 64)       0         \n"," ooling2D)                                                       \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 28, 28, 128)       401536    \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 28, 28, 128)      512       \n"," hNormalization)                                                 \n","                                                                 \n"," average_pooling2d_1 (Averag  (None, 14, 14, 128)      0         \n"," ePooling2D)                                                     \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 12, 12, 256)       295168    \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 12, 12, 256)      1024      \n"," hNormalization)                                                 \n","                                                                 \n"," average_pooling2d_2 (Averag  (None, 6, 6, 256)        0         \n"," ePooling2D)                                                     \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 4, 4, 512)         1180160   \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 4, 4, 512)        2048      \n"," hNormalization)                                                 \n","                                                                 \n"," average_pooling2d_3 (Averag  (None, 2, 2, 512)        0         \n"," ePooling2D)                                                     \n","                                                                 \n"," batch_normalization_4 (Batc  (None, 2, 2, 512)        2048      \n"," hNormalization)                                                 \n","                                                                 \n"," flatten (Flatten)           (None, 2048)              0         \n","                                                                 \n"," batch_normalization_5 (Batc  (None, 2048)             8192      \n"," hNormalization)                                                 \n","                                                                 \n"," dropout (Dropout)           (None, 2048)              0         \n","                                                                 \n"," dense (Dense)               (None, 1024)              2098176   \n","                                                                 \n"," dropout_1 (Dropout)         (None, 1024)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               262400    \n","                                                                 \n"," dropout_2 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 64)                16448     \n","                                                                 \n"," dense_3 (Dense)             (None, 32)                2080      \n","                                                                 \n"," dense_4 (Dense)             (None, 8)                 264       \n","                                                                 \n","=================================================================\n","Total params: 4,273,512\n","Trainable params: 4,266,472\n","Non-trainable params: 7,040\n","_________________________________________________________________\n","None\n","Epoch 1/30\n","1053/1053 [==============================] - 116s 93ms/step - loss: 2.1154 - accuracy: 0.2383 - val_loss: 1.7455 - val_accuracy: 0.3535\n","Epoch 2/30\n","1053/1053 [==============================] - 95s 90ms/step - loss: 1.7692 - accuracy: 0.3437 - val_loss: 1.7884 - val_accuracy: 0.3275\n","Epoch 3/30\n","1053/1053 [==============================] - 97s 92ms/step - loss: 1.6549 - accuracy: 0.3942 - val_loss: 1.5108 - val_accuracy: 0.4846\n","Epoch 4/30\n","1053/1053 [==============================] - 96s 91ms/step - loss: 1.5663 - accuracy: 0.4389 - val_loss: 1.5700 - val_accuracy: 0.4510\n","Epoch 5/30\n","1053/1053 [==============================] - 94s 89ms/step - loss: 1.5095 - accuracy: 0.4637 - val_loss: 1.4345 - val_accuracy: 0.5071\n","Epoch 6/30\n","1053/1053 [==============================] - 93s 89ms/step - loss: 1.4490 - accuracy: 0.4921 - val_loss: 1.4136 - val_accuracy: 0.5202\n","Epoch 7/30\n","1053/1053 [==============================] - 94s 89ms/step - loss: 1.3902 - accuracy: 0.5135 - val_loss: 1.3277 - val_accuracy: 0.5496\n","Epoch 8/30\n","1053/1053 [==============================] - 95s 90ms/step - loss: 1.3524 - accuracy: 0.5269 - val_loss: 1.4394 - val_accuracy: 0.5033\n","Epoch 9/30\n","1053/1053 [==============================] - 96s 91ms/step - loss: 1.3071 - accuracy: 0.5444 - val_loss: 1.2344 - val_accuracy: 0.5744\n","Epoch 10/30\n","1053/1053 [==============================] - 96s 91ms/step - loss: 1.2761 - accuracy: 0.5566 - val_loss: 1.2611 - val_accuracy: 0.5669\n","Epoch 11/30\n","1053/1053 [==============================] - 95s 90ms/step - loss: 1.2386 - accuracy: 0.5728 - val_loss: 1.1875 - val_accuracy: 0.5990\n","Epoch 12/30\n","1053/1053 [==============================] - 95s 90ms/step - loss: 1.2041 - accuracy: 0.5846 - val_loss: 1.2376 - val_accuracy: 0.5731\n","Epoch 13/30\n","1053/1053 [==============================] - 95s 91ms/step - loss: 1.1692 - accuracy: 0.5962 - val_loss: 1.1448 - val_accuracy: 0.6129\n","Epoch 14/30\n","1053/1053 [==============================] - 94s 90ms/step - loss: 1.1305 - accuracy: 0.6121 - val_loss: 1.2283 - val_accuracy: 0.5862\n","Epoch 15/30\n","1053/1053 [==============================] - 95s 90ms/step - loss: 1.1005 - accuracy: 0.6164 - val_loss: 1.3438 - val_accuracy: 0.5442\n","Epoch 16/30\n","1053/1053 [==============================] - 95s 90ms/step - loss: 1.0617 - accuracy: 0.6348 - val_loss: 1.2791 - val_accuracy: 0.5771\n","Epoch 17/30\n","1053/1053 [==============================] - 94s 89ms/step - loss: 1.0272 - accuracy: 0.6435 - val_loss: 1.0789 - val_accuracy: 0.6305\n","Epoch 18/30\n","1053/1053 [==============================] - 95s 90ms/step - loss: 0.9897 - accuracy: 0.6559 - val_loss: 1.1735 - val_accuracy: 0.6126\n","Epoch 19/30\n","1053/1053 [==============================] - 94s 90ms/step - loss: 0.9510 - accuracy: 0.6724 - val_loss: 1.1453 - val_accuracy: 0.6102\n","Epoch 20/30\n","1053/1053 [==============================] - 95s 91ms/step - loss: 0.9120 - accuracy: 0.6819 - val_loss: 1.0891 - val_accuracy: 0.6580\n","Epoch 21/30\n","1053/1053 [==============================] - 95s 90ms/step - loss: 0.8822 - accuracy: 0.6953 - val_loss: 1.0846 - val_accuracy: 0.6476\n","Epoch 22/30\n","1053/1053 [==============================] - 96s 91ms/step - loss: 0.8482 - accuracy: 0.7052 - val_loss: 1.0012 - val_accuracy: 0.6727\n","Epoch 23/30\n","1053/1053 [==============================] - 96s 91ms/step - loss: 0.8319 - accuracy: 0.7145 - val_loss: 1.0614 - val_accuracy: 0.6447\n","Epoch 24/30\n","1053/1053 [==============================] - 97s 93ms/step - loss: 0.7785 - accuracy: 0.7334 - val_loss: 1.0262 - val_accuracy: 0.6698\n","Epoch 25/30\n","1053/1053 [==============================] - 96s 91ms/step - loss: 0.7296 - accuracy: 0.7477 - val_loss: 1.1040 - val_accuracy: 0.6375\n","Epoch 26/30\n","1053/1053 [==============================] - 98s 93ms/step - loss: 0.7071 - accuracy: 0.7563 - val_loss: 1.1849 - val_accuracy: 0.6356\n","Epoch 27/30\n","1053/1053 [==============================] - 96s 91ms/step - loss: 0.6628 - accuracy: 0.7714 - val_loss: 1.1452 - val_accuracy: 0.6503\n","Epoch 28/30\n","1053/1053 [==============================] - 96s 91ms/step - loss: 0.6353 - accuracy: 0.7816 - val_loss: 1.0992 - val_accuracy: 0.6522\n","Epoch 29/30\n","1053/1053 [==============================] - 95s 90ms/step - loss: 0.5924 - accuracy: 0.7954 - val_loss: 1.0123 - val_accuracy: 0.6888\n","Epoch 30/30\n","1053/1053 [==============================] - 95s 90ms/step - loss: 0.5658 - accuracy: 0.8042 - val_loss: 1.2532 - val_accuracy: 0.6367\n","62/62 [==============================] - 3s 41ms/step - loss: 1.2336 - accuracy: 0.6431\n","[1.2336289882659912, 0.6431472301483154]\n"]}],"source":["model = Sequential()\n","model.add(Conv2D(filters=64, kernel_size=[7,7], kernel_initializer = initializers.he_normal(seed=1), activation=\"relu\", input_shape=(128,128,1)))\n","# Dim = (122x122x64)\n","model.add(BatchNormalization())\n","model.add(AveragePooling2D(pool_size=[2,2], strides=2))\n","# Dim = (61x61x64)\n","model.add(Conv2D(filters=128, kernel_size=[7,7], strides=2, kernel_initializer = initializers.he_normal(seed=1), activation=\"relu\"))\n","# Dim = (28x28x128)\n","model.add(BatchNormalization())\n","model.add(AveragePooling2D(pool_size=[2,2], strides=2))\n","# Dim = (14x14x128)\n","model.add(Conv2D(filters=256, kernel_size=[3,3], kernel_initializer = initializers.he_normal(seed=1), activation=\"relu\"))\n","# Dim = (12x12x256)\n","model.add(BatchNormalization())\n","model.add(AveragePooling2D(pool_size=[2,2], strides=2))\n","# Dim = (6x6x256)\n","model.add(Conv2D(filters=512, kernel_size=[3,3], kernel_initializer = initializers.he_normal(seed=1), activation=\"relu\"))\n","# Dim = (4x4x512)\n","model.add(BatchNormalization())\n","model.add(AveragePooling2D(pool_size=[2,2], strides=2))\n","# Dim = (2x2x512)\n","model.add(BatchNormalization())\n","model.add(Flatten())\n","# Dim = (2048)\n","model.add(BatchNormalization())\n","model.add(Dropout(0.6))\n","model.add(Dense(1024, activation=\"relu\", kernel_initializer=initializers.he_normal(seed=1)))\n","# Dim = (1024)\n","model.add(Dropout(0.5))\n","model.add(Dense(256, activation=\"relu\", kernel_initializer=initializers.he_normal(seed=1)))\n","# Dim = (256)\n","model.add(Dropout(0.25))\n","model.add(Dense(64, activation=\"relu\", kernel_initializer=initializers.he_normal(seed=1)))\n","# Dim = (64)\n","model.add(Dense(32, activation=\"relu\", kernel_initializer=initializers.he_normal(seed=1)))\n","# Dim = (32)\n","model.add(Dense(n_classes, activation=\"softmax\", kernel_initializer=initializers.he_normal(seed=1)))\n","# Dim = (8)\n","print(model.summary())\n","# plot_model(model, to_file=\"Saved_Model/Model_Architecture.jpg\")\n","model.compile(loss=\"categorical_crossentropy\", optimizer=tf.optimizers.Adam(lr=0.0001), metrics=['accuracy'])\n","pd.DataFrame(model.fit(train_x, train_y, epochs=30, verbose=1, validation_split=0.1).history).to_csv(\"/content/drive/MyDrive/IR Project/Saved_Model/training_history.csv\")\n","score = model.evaluate(test_x, test_y, verbose=1)\n","print(score)\n","model.save(\"/content/drive/MyDrive/IR Project/Saved_Model/Model.h5\")"]},{"cell_type":"code","source":["def get_genre(url, online=True):\n","    model = keras.models.load_model(\"/content/drive/MyDrive/IR Project/Saved_Model/Model.h5\")\n","    genre = {\n","        0: \"Hip-Hop\",\n","        1: \"International\",\n","        2: \"Electronic\",\n","        3: \"Folk\",\n","        4: \"Experimental\",\n","        5: \"Rock\",\n","        6: \"Pop\",\n","        7: \"Instrumental\"\n","        }\n","    if online:\n","        inputs = get_data_online_url(url)\n","    else:\n","        inputs = get_data(url)\n","    outputs = model(inputs)\n","    output = np.argmax(outputs, axis=1)\n","    return [genre[label] for label in output]\n","\n","def get_embeddings(url, online=True):\n","    raw_model = keras.models.load_model(\"/content/drive/MyDrive/IR Project/Saved_Model/Model.h5\")\n","    model = Model(inputs=raw_model.input, outputs=raw_model.layers[-2].output)\n","    if online:\n","        inputs = get_data_online_url(url)\n","    else:\n","        inputs = get_data(url)\n","    outputs = model(inputs)\n","    output = np.mean(outputs, axis=0)\n","    return output"],"metadata":{"id":"wbvAlSXfk074","executionInfo":{"status":"ok","timestamp":1650455621886,"user_tz":-330,"elapsed":362,"user":{"displayName":"Abhinav Suresh Ennazhiyil","userId":"02866869318925835569"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["url = \"/content/drive/MyDrive/IR Project/Data/test/the-cradle-of-your-soul-15700.mp3\""],"metadata":{"id":"Df0C7yMTnDcg","executionInfo":{"status":"ok","timestamp":1650455625210,"user_tz":-330,"elapsed":355,"user":{"displayName":"Abhinav Suresh Ennazhiyil","userId":"02866869318925835569"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["get_embeddings(url, online=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MxXZcUn_nMWR","executionInfo":{"status":"ok","timestamp":1650455654845,"user_tz":-330,"elapsed":27955,"user":{"displayName":"Abhinav Suresh Ennazhiyil","userId":"02866869318925835569"}},"outputId":"28944ec4-37b1-4d02-b15c-e8efbd74e08a"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating Spectogram...\n","Slicing Spectogram...\n","Converting to numpy array\n"]},{"output_type":"execute_result","data":{"text/plain":["array([0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       2.2191207e+04, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       1.3199707e+04, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 0.0000000e+00, 2.9160959e+04, 0.0000000e+00,\n","       5.8543970e+03, 0.0000000e+00, 0.0000000e+00, 6.2868921e+03,\n","       0.0000000e+00, 0.0000000e+00, 1.3185873e+04, 9.4970398e+00,\n","       1.2568900e+04, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n","       0.0000000e+00, 2.3969320e+04, 0.0000000e+00, 0.0000000e+00],\n","      dtype=float32)"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["get_genre(url, online=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0VSIbEMHnOB3","executionInfo":{"status":"ok","timestamp":1650455692020,"user_tz":-330,"elapsed":21315,"user":{"displayName":"Abhinav Suresh Ennazhiyil","userId":"02866869318925835569"}},"outputId":"d7a7061f-5d9e-461a-e1b1-cca55e53d394"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating Spectogram...\n","Slicing Spectogram...\n","Converting to numpy array\n"]},{"output_type":"execute_result","data":{"text/plain":["['Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental',\n"," 'Experimental']"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":[""],"metadata":{"id":"MZWQz1m20uwl"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"IR - training.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}