{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9941,"status":"ok","timestamp":1649955058639,"user":{"displayName":"Abhinav Suresh Ennazhiyil","userId":"02866869318925835569"},"user_tz":-330},"id":"X0SvBgI8-_ub","outputId":"91287deb-662d-4001-a9e7-cfa20e1210d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n","Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n","Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.5)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.2)\n","Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.6.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.8)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n","Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.0.4)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n","Requirement already satisfied: mir_eval in /usr/local/lib/python3.7/dist-packages (0.7)\n","Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.21.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.15.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from mir_eval) (0.16.0)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.4.1)\n"]}],"source":["!pip install librosa\n","!pip install mir_eval"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5381,"status":"ok","timestamp":1649955064014,"user":{"displayName":"Abhinav Suresh Ennazhiyil","userId":"02866869318925835569"},"user_tz":-330},"id":"PhCH-pTtHAHw","outputId":"fdcd0e75-fa13-4194-96c1-d1ee4a7eab41"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":9991,"status":"ok","timestamp":1649955074001,"user":{"displayName":"Abhinav Suresh Ennazhiyil","userId":"02866869318925835569"},"user_tz":-330},"id":"YcgqexjdAbH7"},"outputs":[],"source":["import librosa\n","import librosa.display as dsp\n","import mir_eval\n","from IPython.display import Audio\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import pandas as pd\n","import re\n","import math\n","import numpy as np\n","from PIL import Image\n","import joblib\n","import cv2\n","from keras.utils import np_utils\n","from sklearn.model_selection import train_test_split\n","from tensorflow import keras\n","import tensorflow as tf \n","import random\n","from keras.models import Sequential\n","from keras import initializers\n","from keras import optimizers\n","# from keras.utils import plot_model\n","from keras.layers import *\n","import pandas as pd\n","from tqdm.notebook import tqdm\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1649955074002,"user":{"displayName":"Abhinav Suresh Ennazhiyil","userId":"02866869318925835569"},"user_tz":-330},"id":"D2mNt_E2Adwv"},"outputs":[],"source":["def create_spectrogram(verbose=0, mode=None, continue_=6647):\n","    if mode == \"Train\":\n","        if os.path.exists('/content/drive/MyDrive/IR Project/Train_Spectogram_Images'):\n","            return\n","        # Get Genres and Track IDs from the tracks.csv file\n","        filename_metadata = \"/content/drive/MyDrive/IR Project/Data/fma_metadata/tracks.csv\"\n","        tracks = pd.read_csv(filename_metadata, header=2, low_memory=False)\n","        tracks_array = tracks.values\n","        tracks_id_array = tracks_array[: , 0]\n","        tracks_genre_array = tracks_array[: , 40]\n","        tracks_id_array = tracks_id_array.reshape(tracks_id_array.shape[0], )\n","        tracks_genre_array = tracks_genre_array.reshape(tracks_genre_array.shape[0], )\n","        folder_sample = \"/content/drive/MyDrive/IR Project/Data/fma_small\"\n","        directories = [d for d in os.listdir(folder_sample)\n","                       if os.path.isdir(os.path.join(folder_sample, d))]\n","        counter = 0\n","        if(verbose > 0):\n","            print(\"Converting mp3 audio files into mel Spectograms ...\")\n","        if not os.path.exists('/content/drive/MyDrive/IR Project/Train_Spectogram_Images'):\n","            os.makedirs('/content/drive/MyDrive/IR Project/Train_Spectogram_Images')\n","        labels = [os.path.join(folder_sample, d) for d in directories]\n","        total = 0\n","        for l in labels:\n","            total += len([f for f in os.listdir(l) if f.endswith(\".mp3\")])\n","        with tqdm(total = total) as pbar:\n","            for d in directories:\n","                label_directory = os.path.join(folder_sample, d)\n","                file_names = [os.path.join(label_directory, f)\n","                            for f in os.listdir(label_directory)\n","                            if f.endswith(\".mp3\")]\n","\n","                # Convert .mp3 files into mel-Spectograms\n","                for f in file_names:\n","                    counter += 1\n","                    pbar.update(1)\n","                    if counter <= continue_:\n","                        continue\n","                    track_id = int(re.search('/content/drive/MyDrive/IR Project/Data/fma_small/.*/(.+?).mp3', f).group(1))\n","                    try:\n","                        track_index = list(tracks_id_array).index(track_id)\n","                    except ValueError:\n","                        print(f\"Error: Track ID {track_id} not found in tracks.csv file.\")\n","                        continue\n","                    if(str(tracks_genre_array[track_index]) != '0'):\n","                        try:\n","                            y, sr = librosa.load(f)\n","                        except Exception:\n","                            print(f\"Couldn't convert {track_id}\")\n","                        melspectrogram_array = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128,fmax=8000)\n","                        mel = librosa.power_to_db(melspectrogram_array)\n","                        # Length and Width of Spectogram\n","                        fig_size = plt.rcParams[\"figure.figsize\"]\n","                        fig_size[0] = float(mel.shape[1]) // float(100)\n","                        fig_size[1] = float(mel.shape[0]) // float(100)\n","                        plt.rcParams[\"figure.figsize\"] = fig_size\n","                        plt.axis('off')\n","                        plt.axes([0., 0., 1., 1.0], frameon=False, xticks=[], yticks=[])\n","                        librosa.display.specshow(mel, cmap='gray_r')\n","                        plt.savefig(\"/content/drive/MyDrive/IR Project/Train_Spectogram_Images/\"+str(counter)+\"_\"+str(tracks_genre_array[track_index])+\".jpg\", bbox_inches=None, pad_inches=0)\n","                        plt.close()\n","                    \n","        return\n","\n","    elif mode == \"Test\":\n","        if os.path.exists('/content/drive/MyDrive/IR Project/Test_Spectogram_Images'):\n","            return\n","\n","        folder_sample = \"/content/drive/MyDrive/IR Project/Data/DLMusicTest_30\"\n","        counter = 0\n","        if(verbose > 0):\n","            print(\"Converting mp3 audio files into mel Spectograms ...\")\n","        if not os.path.exists('/content/drive/MyDrive/IR Project/Test_Sepctogram_Images'):\n","            os.makedirs('/content/drive/MyDrive/IR Project/Test_Spectogram_Images')\n","        file_names = [os.path.join(folder_sample, f) for f in os.listdir(folder_sample)\n","                       if f.endswith(\".mp3\")]\n","        # Convert .mp3 files into mel-Spectograms\n","        for f in file_names:\n","            test_id = re.search('/content/drive/MyDrive/IR Project/Data/DLMusicTest_30/(.+?).mp3', f).group(1)\n","            y, sr = librosa.load(f)\n","            melspectrogram_array = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128,fmax=8000)\n","            mel = librosa.power_to_db(melspectrogram_array)\n","            # Length and Width of Spectogram\n","            fig_size = plt.rcParams[\"figure.figsize\"]\n","            fig_size[0] = float(mel.shape[1]) // float(100)\n","            fig_size[1] = float(mel.shape[0]) // float(100)\n","            plt.rcParams[\"figure.figsize\"] = fig_size\n","            plt.axis('off')\n","            plt.axes([0., 0., 1., 1.0], frameon=False, xticks=[], yticks=[])\n","            librosa.display.specshow(mel, cmap='gray_r')\n","            plt.savefig(\"/content/drive/MyDrive/IR Project/Test_Spectogram_Images/\"+test_id+\".jpg\", cmap='gray_r', bbox_inches=None, pad_inches=0)\n","            plt.close()\n","        return"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1649955074002,"user":{"displayName":"Abhinav Suresh Ennazhiyil","userId":"02866869318925835569"},"user_tz":-330},"id":"nQZIK8fFGn4V"},"outputs":[],"source":["def slice_spect(verbose=0, mode=None):\n","    if mode==\"Train\":\n","        if os.path.exists('/content/drive/MyDrive/IR Project/Train_Sliced_Images'):\n","            return\n","        labels = []\n","        image_folder = \"/content/drive/MyDrive/IR Project/Train_Spectogram_Images\"\n","        filenames = [os.path.join(image_folder, f) for f in os.listdir(image_folder)\n","                       if f.endswith(\".jpg\")]\n","        counter = 0\n","        if(verbose > 0):\n","            print(\"Slicing Spectograms ...\")\n","        if not os.path.exists('/content/drive/MyDrive/IR Project/Train_Sliced_Images'):\n","            os.makedirs('/content/drive/MyDrive/IR Project/Train_Sliced_Images')\n","        for f in tqdm(filenames):\n","            genre_variable = re.search('/content/drive/MyDrive/IR Project/Train_Spectogram_Images/.*_(.+?).jpg', f).group(1)\n","            img = Image.open(f)\n","            subsample_size = 128\n","            width, height = img.size\n","            number_of_samples = width // subsample_size\n","            for i in range(number_of_samples):\n","                start = i*subsample_size\n","                img_temporary = img.crop((start, 0., start + subsample_size, subsample_size))\n","                img_temporary.save(\"/content/drive/MyDrive/IR Project/Train_Sliced_Images/\"+str(counter)+\"_\"+genre_variable+\".jpg\")\n","                counter = counter + 1\n","        return\n","\n","    elif mode==\"Test\":\n","        if os.path.exists('/content/drive/MyDrive/IR Project/Test_Sliced_Images'):\n","            return\n","        labels = []\n","        image_folder = \"/content/drive/MyDrive/IR Project/Test_Spectogram_Images\"\n","        filenames = [os.path.join(image_folder, f) for f in os.listdir(image_folder)\n","                       if f.endswith(\".jpg\")]\n","        counter = 0\n","        if(verbose > 0):\n","            print(\"Slicing Spectograms ...\")\n","        if not os.path.exists('/content/drive/MyDrive/IR Project/Test_Sliced_Images'):\n","            os.makedirs('/content/drive/MyDrive/IR Project/Test_Sliced_Images')\n","        for f in filenames:\n","            song_variable = re.search('/content/drive/MyDrive/IR Project/Test_Spectogram_Images/(.+?).jpg', f).group(1)\n","            img = Image.open(f)\n","            subsample_size = 128\n","            width, height = img.size\n","            number_of_samples = width // subsample_size\n","            for i in range(number_of_samples):\n","                start = i*subsample_size\n","                img_temporary = img.crop((start, 0., start + subsample_size, subsample_size))\n","                img_temporary.save(\"/content/drive/MyDrive/IR Project/Test_Sliced_Images/\"+str(counter)+\"_\"+song_variable+\".jpg\")\n","                counter = counter + 1\n","        return"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1649955074003,"user":{"displayName":"Abhinav Suresh Ennazhiyil","userId":"02866869318925835569"},"user_tz":-330},"id":"rqDB2VIdHPko"},"outputs":[],"source":["def load_dataset(verbose=0, mode=None, datasetSize=1.0):\n","    if os.path.exists('/content/drive/MyDrive/IR Project/Training_Data'):\n","            print(\"yes\")\n","            train_x = np.load(\"/content/drive/MyDrive/IR Project/Training_Data/train_x.npy\")\n","            train_y = np.load(\"/content/drive/MyDrive/IR Project/Training_Data/train_y.npy\")\n","            test_x = np.load(\"/content/drive/MyDrive/IR Project/Training_Data/test_x.npy\")\n","            test_y = np.load(\"/content/drive/MyDrive/IR Project/Training_Data/test_y.npy\")\n","            n_classes, genre_new = joblib.load(\"/content/drive/MyDrive/IR Project/Training_Data/meta.pkl\")\n","            return train_x, train_y, test_x, test_y, n_classes, genre_new\n","    create_spectrogram(verbose, mode)\n","    slice_spect(verbose, mode)\n","\n","    # datasetSize is a float value which returns a fraction of the dataset.\n","    # If set as 1.0 it returns the entire dataset.\n","    # If set as 0.5 it returns half the dataset.\n","\n","    if mode==\"Train\":\n","        genre = {\n","        \"Hip-Hop\": 0,\n","        \"International\": 1,\n","        \"Electronic\": 2,\n","        \"Folk\" : 3,\n","        \"Experimental\": 4,\n","        \"Rock\": 5,\n","        \"Pop\": 6,\n","        \"Instrumental\": 7\n","        }\n","        if(verbose > 0):\n","            print(\"Compiling Training and Testing Sets ...\")\n","        filenames = [os.path.join(\"/content/drive/MyDrive/IR Project/Train_Sliced_Images\", f) for f in os.listdir(\"/content/drive/MyDrive/IR Project/Train_Sliced_Images\")\n","                       if f.endswith(\".jpg\")]\n","        images_all = [None]*(len(filenames))\n","        labels_all = [None]*(len(filenames))\n","        for f in tqdm(filenames):\n","            index = int(re.search('/content/drive/MyDrive/IR Project/Train_Sliced_Images/(.+?)_.*.jpg', f).group(1))\n","            genre_variable = re.search('/content/drive/MyDrive/IR Project/Train_Sliced_Images/.*_(.+?).jpg', f).group(1)\n","            temp = cv2.imread(f, cv2.IMREAD_UNCHANGED)\n","            images_all[index] = cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY)\n","            labels_all[index] = genre[genre_variable]\n","\n","        if(datasetSize == 1.0):\n","            images = images_all\n","            labels = labels_all\n","\n","        else:\n","            count_max = int(len(images_all)*datasetSize / 8.0)\n","            count_array = [0, 0, 0, 0, 0 ,0, 0, 0]\n","            images = []\n","            labels = []\n","            for i in range(0, len(images_all)):\n","                if(count_array[labels_all[i]] < count_max):\n","                    images.append(images_all[i])\n","                    labels.append(labels_all[i])\n","                    count_array[labels_all[i]] += 1\n","            images = np.array(images)\n","            labels = np.array(labels)\n","\n","        images = np.array(images)\n","        labels = np.array(labels)\n","        labels = labels.reshape(labels.shape[0],1)\n","        train_x, test_x, train_y, test_y = train_test_split(images, labels, test_size=0.05, shuffle=True)\n","\n","        # Convert the labels into one-hot vectors.\n","        train_y = np_utils.to_categorical(train_y)\n","        test_y = np_utils.to_categorical(test_y, num_classes=8)\n","        n_classes = len(genre)\n","        genre_new = {value: key for key, value in genre.items()}\n","\n","        if not os.path.exists('/content/drive/MyDrive/IR Project/Training_Data'):\n","            print(\"no\")\n","            os.makedirs('/content/drive/MyDrive/IR Project/Training_Data')\n","        np.save(\"/content/drive/MyDrive/IR Project/Training_Data/train_x.npy\", train_x)\n","        np.save(\"/content/drive/MyDrive/IR Project/Training_Data/train_y.npy\", train_y)\n","        np.save(\"/content/drive/MyDrive/IR Project/Training_Data/test_x.npy\", test_x)\n","        np.save(\"/content/drive/MyDrive/IR Project/Training_Data/test_y.npy\", test_y)\n","        joblib.dump((n_classes, genre_new), \"/content/drive/MyDrive/IR Project/Training_Data/meta.pkl\")\n","        return train_x, train_y, test_x, test_y, n_classes, genre_new\n","\n","    if mode==\"Test\":\n","        if(verbose > 0):\n","            print(\"Compiling Training and Testing Sets ...\")\n","        filenames = [os.path.join(\"/content/drive/MyDrive/IR Project/Test_Sliced_Images\", f) for f in os.listdir(\"/content/drive/MyDrive/IR Project/Test_Sliced_Images\")\n","                       if f.endswith(\".jpg\")]\n","        images = []\n","        labels = []\n","        for f in filenames:\n","            song_variable = re.search('/content/drive/MyDrive/IR Project/Test_Sliced_Images/.*_(.+?).jpg', f).group(1)\n","            tempImg = cv2.imread(f, cv2.IMREAD_UNCHANGED)\n","            images.append(cv2.cvtColor(tempImg, cv2.COLOR_BGR2GRAY))\n","            labels.append(song_variable)\n","\n","        images = np.array(images)\n","\n","        return images, labels"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5919,"status":"ok","timestamp":1649955079914,"user":{"displayName":"Abhinav Suresh Ennazhiyil","userId":"02866869318925835569"},"user_tz":-330},"id":"7FwcZ3WSKGUJ","outputId":"74565287-d183-4310-e3d4-89aaf4a8f09e"},"outputs":[{"output_type":"stream","name":"stdout","text":["yes\n"]}],"source":["train_x, train_y, test_x, test_y, n_classes, genre = load_dataset(verbose=1, mode=\"Train\", datasetSize=0.75)\n","# datasetSize = 0.75, this returns 3/4th of the dataset.\n","\n","# Expand the dimensions of the image to have a channel dimension. (nx128x128) ==> (nx128x128x1)\n","train_x = train_x.reshape(train_x.shape[0], train_x.shape[1], train_x.shape[2], 1)\n","test_x = test_x.reshape(test_x.shape[0], test_x.shape[1], test_x.shape[2], 1)\n","\n","# Normalize the matrices.\n","train_x = train_x / 255.\n","test_x = test_x / 255."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wNiXSZGFHmsB","outputId":"ada9fba8-86e4-4d53-a183-96df8d73d62f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 122, 122, 64)      3200      \n","                                                                 \n"," batch_normalization (BatchN  (None, 122, 122, 64)     256       \n"," ormalization)                                                   \n","                                                                 \n"," average_pooling2d (AverageP  (None, 61, 61, 64)       0         \n"," ooling2D)                                                       \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 28, 28, 128)       401536    \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 28, 28, 128)      512       \n"," hNormalization)                                                 \n","                                                                 \n"," average_pooling2d_1 (Averag  (None, 14, 14, 128)      0         \n"," ePooling2D)                                                     \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 12, 12, 256)       295168    \n","                                                                 \n"," batch_normalization_2 (Batc  (None, 12, 12, 256)      1024      \n"," hNormalization)                                                 \n","                                                                 \n"," average_pooling2d_2 (Averag  (None, 6, 6, 256)        0         \n"," ePooling2D)                                                     \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 4, 4, 512)         1180160   \n","                                                                 \n"," batch_normalization_3 (Batc  (None, 4, 4, 512)        2048      \n"," hNormalization)                                                 \n","                                                                 \n"," average_pooling2d_3 (Averag  (None, 2, 2, 512)        0         \n"," ePooling2D)                                                     \n","                                                                 \n"," batch_normalization_4 (Batc  (None, 2, 2, 512)        2048      \n"," hNormalization)                                                 \n","                                                                 \n"," flatten (Flatten)           (None, 2048)              0         \n","                                                                 \n"," batch_normalization_5 (Batc  (None, 2048)             8192      \n"," hNormalization)                                                 \n","                                                                 \n"," dropout (Dropout)           (None, 2048)              0         \n","                                                                 \n"," dense (Dense)               (None, 1024)              2098176   \n","                                                                 \n"," dropout_1 (Dropout)         (None, 1024)              0         \n","                                                                 \n"," dense_1 (Dense)             (None, 256)               262400    \n","                                                                 \n"," dropout_2 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 64)                16448     \n","                                                                 \n"," dense_3 (Dense)             (None, 32)                2080      \n","                                                                 \n"," dense_4 (Dense)             (None, 8)                 264       \n","                                                                 \n","=================================================================\n","Total params: 4,273,512\n","Trainable params: 4,266,472\n","Non-trainable params: 7,040\n","_________________________________________________________________\n","None\n","Epoch 1/20\n","1053/1053 [==============================] - 115s 97ms/step - loss: 2.1075 - accuracy: 0.2451 - val_loss: 1.7041 - val_accuracy: 0.3631\n","Epoch 2/20\n","1053/1053 [==============================] - 99s 94ms/step - loss: 1.7591 - accuracy: 0.3493 - val_loss: 1.5970 - val_accuracy: 0.4253\n","Epoch 3/20\n","1053/1053 [==============================] - 99s 94ms/step - loss: 1.6525 - accuracy: 0.3985 - val_loss: 1.5351 - val_accuracy: 0.4486\n","Epoch 4/20\n"," 556/1053 [==============>...............] - ETA: 44s - loss: 1.5766 - accuracy: 0.4345"]}],"source":["model = Sequential()\n","model.add(Conv2D(filters=64, kernel_size=[7,7], kernel_initializer = initializers.he_normal(seed=1), activation=\"relu\", input_shape=(128,128,1)))\n","# Dim = (122x122x64)\n","model.add(BatchNormalization())\n","model.add(AveragePooling2D(pool_size=[2,2], strides=2))\n","# Dim = (61x61x64)\n","model.add(Conv2D(filters=128, kernel_size=[7,7], strides=2, kernel_initializer = initializers.he_normal(seed=1), activation=\"relu\"))\n","# Dim = (28x28x128)\n","model.add(BatchNormalization())\n","model.add(AveragePooling2D(pool_size=[2,2], strides=2))\n","# Dim = (14x14x128)\n","model.add(Conv2D(filters=256, kernel_size=[3,3], kernel_initializer = initializers.he_normal(seed=1), activation=\"relu\"))\n","# Dim = (12x12x256)\n","model.add(BatchNormalization())\n","model.add(AveragePooling2D(pool_size=[2,2], strides=2))\n","# Dim = (6x6x256)\n","model.add(Conv2D(filters=512, kernel_size=[3,3], kernel_initializer = initializers.he_normal(seed=1), activation=\"relu\"))\n","# Dim = (4x4x512)\n","model.add(BatchNormalization())\n","model.add(AveragePooling2D(pool_size=[2,2], strides=2))\n","# Dim = (2x2x512)\n","model.add(BatchNormalization())\n","model.add(Flatten())\n","# Dim = (2048)\n","model.add(BatchNormalization())\n","model.add(Dropout(0.6))\n","model.add(Dense(1024, activation=\"relu\", kernel_initializer=initializers.he_normal(seed=1)))\n","# Dim = (1024)\n","model.add(Dropout(0.5))\n","model.add(Dense(256, activation=\"relu\", kernel_initializer=initializers.he_normal(seed=1)))\n","# Dim = (256)\n","model.add(Dropout(0.25))\n","model.add(Dense(64, activation=\"relu\", kernel_initializer=initializers.he_normal(seed=1)))\n","# Dim = (64)\n","model.add(Dense(32, activation=\"relu\", kernel_initializer=initializers.he_normal(seed=1)))\n","# Dim = (32)\n","model.add(Dense(n_classes, activation=\"softmax\", kernel_initializer=initializers.he_normal(seed=1)))\n","# Dim = (8)\n","print(model.summary())\n","# plot_model(model, to_file=\"Saved_Model/Model_Architecture.jpg\")\n","model.compile(loss=\"categorical_crossentropy\", optimizer=tf.optimizers.Adam(lr=0.0001), metrics=['accuracy'])\n","pd.DataFrame(model.fit(train_x, train_y, epochs=20, verbose=1, validation_split=0.1).history).to_csv(\"/content/drive/MyDrive/IR Project/Saved_Model/training_history.csv\")\n","score = model.evaluate(test_x, test_y, verbose=1)\n","print(score)\n","model.save(\"/content/drive/MyDrive/IR Project/Saved_Model/Model.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4asNkR1vHobt"},"outputs":[],"source":[""]}],"metadata":{"colab":{"collapsed_sections":[],"name":"IR - training.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}